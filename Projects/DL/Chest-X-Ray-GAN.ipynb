{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":23812,"sourceType":"datasetVersion","datasetId":17810}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/yaramahrous/chest-x-ray-gan?scriptVersionId=201487036\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"<div style=\"\n  background-color: #e3f2fd;\n  padding: 15px;\n  border-left: 6px solid #0d47a1;\n  border-radius: 8px;\n  font-family: 'Georgia', serif;\n  color: #01579b;\n  font-size: 28px;\n  text-align: center;\n  font-weight: bold;\n\">\n  üìö Import Libraries\n</div>\n","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nfrom tqdm import tqdm\nimport cv2\nimport os\nimport seaborn as sns\nfrom keras.models import Sequential, Model\nfrom keras.layers import Dense, Flatten, Conv2D, Reshape, Input, Conv2DTranspose\nfrom keras.layers import Activation, LeakyReLU, BatchNormalization, Dropout, Resizing\nfrom tensorflow.keras import layers\nfrom keras.losses import BinaryCrossentropy\nfrom tensorflow.keras.applications import VGG16\nimport random\nimport glob\nimport albumentations as A\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\nimport warnings\nwarnings.filterwarnings('ignore')\n","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-10-16T10:21:43.058034Z","iopub.status.busy":"2024-10-16T10:21:43.057721Z","iopub.status.idle":"2024-10-16T10:21:58.155472Z","shell.execute_reply":"2024-10-16T10:21:58.154279Z","shell.execute_reply.started":"2024-10-16T10:21:43.057981Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<div style=\"\n  background-color: #e3f2fd;\n  padding: 15px;\n  border-left: 6px solid #0d47a1;\n  border-radius: 8px;\n  font-family: 'Georgia', serif;\n  color: #01579b;\n  font-size: 28px;\n  text-align: center;\n  font-weight: bold;\n\">\n  üìå Constants\n</div>\n","metadata":{}},{"cell_type":"code","source":"# Directories for the PNEUMONIA class images\ntrain_pneumonia_dir = '/kaggle/input/chest-xray-pneumonia/chest_xray/train/PNEUMONIA'\ntest_pneumonia_dir = '/kaggle/input/chest-xray-pneumonia/chest_xray/test/PNEUMONIA'\nvalid_pneumonia_dir = '/kaggle/input/chest-xray-pneumonia/chest_xray/val/PNEUMONIA'\n\ntarget_size = (128, 128)\nbatch_size = 32\n","metadata":{"execution":{"iopub.execute_input":"2024-10-16T10:21:58.158444Z","iopub.status.busy":"2024-10-16T10:21:58.157661Z","iopub.status.idle":"2024-10-16T10:21:58.163915Z","shell.execute_reply":"2024-10-16T10:21:58.163063Z","shell.execute_reply.started":"2024-10-16T10:21:58.158396Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<div style=\"\n  background-color: #e3f2fd;\n  padding: 15px;\n  border-left: 6px solid #0d47a1;\n  border-radius: 8px;\n  font-family: 'Georgia', serif;\n  color: #01579b;\n  font-size: 28px;\n  text-align: center;\n  font-weight: bold;\n\">\n  ‚öôÔ∏è Functions\n</div>\n","metadata":{}},{"cell_type":"code","source":"def plot_multiple_img(img_matrix_list, title_list, ncols, main_title=\"\"):\n    fig, myaxes = plt.subplots(figsize=(20, 15), nrows=3, ncols=ncols, squeeze=False)\n    fig.suptitle(main_title, fontsize = 30)\n    fig.subplots_adjust(wspace=0.3)\n    fig.subplots_adjust(hspace=0.3)\n    for i, (img, title) in enumerate(zip(img_matrix_list, title_list)):\n        myaxes[i // ncols][i % ncols].imshow(img)\n        myaxes[i // ncols][i % ncols].set_title(title, fontsize=15)\n    plt.show()","metadata":{"execution":{"iopub.execute_input":"2024-10-16T10:21:58.167532Z","iopub.status.busy":"2024-10-16T10:21:58.165543Z","iopub.status.idle":"2024-10-16T10:21:58.193036Z","shell.execute_reply":"2024-10-16T10:21:58.192058Z","shell.execute_reply.started":"2024-10-16T10:21:58.167336Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def load_images_from_folder(folder):\n    images = []\n    for filename in os.listdir(folder):\n        img_path = os.path.join(folder, filename)\n        img = cv2.imread(img_path)\n        if img is not None:\n            image_resized = cv2.resize(img, target_size)\n            images.append(image_resized)\n    return images","metadata":{"execution":{"iopub.execute_input":"2024-10-16T10:21:58.195585Z","iopub.status.busy":"2024-10-16T10:21:58.195243Z","iopub.status.idle":"2024-10-16T10:21:58.202952Z","shell.execute_reply":"2024-10-16T10:21:58.20193Z","shell.execute_reply.started":"2024-10-16T10:21:58.195544Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<div style=\"\n  background-color: #e3f2fd;\n  padding: 15px;\n  border-left: 6px solid #0d47a1;\n  border-radius: 8px;\n  font-family: 'Georgia', serif;\n  color: #01579b;\n  font-size: 28px;\n  text-align: center;\n  font-weight: bold;\n\">\n  üîç Exploring The Data\n\n</div>\n","metadata":{}},{"cell_type":"code","source":"# Look at the training, testing and validation data numbers\ntrain_data = glob.glob('../input/chest-xray-pneumonia/chest_xray/train/**/*.jpeg')\ntest_data = glob.glob('../input/chest-xray-pneumonia/chest_xray/test/**/*.jpeg')\nval_data = glob.glob('../input/chest-xray-pneumonia/chest_xray/val/**/*.jpeg')\n\nprint(f\"Training Set has: {len(train_data)} images\")\nprint(f\"Testing Set has: {len(test_data)} images\")\nprint(f\"Validation Set has: {len(val_data)} images\")","metadata":{"execution":{"iopub.execute_input":"2024-10-16T07:55:50.807764Z","iopub.status.busy":"2024-10-16T07:55:50.806992Z","iopub.status.idle":"2024-10-16T07:55:51.306115Z","shell.execute_reply":"2024-10-16T07:55:51.305193Z","shell.execute_reply.started":"2024-10-16T07:55:50.807719Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"DIR = \"../input/chest-xray-pneumonia/chest_xray/\"\nsets = [\"train\", \"test\", \"val\"]\nall_pneumonia = []\nall_normal = []\n\nfor cat in sets:\n    path = os.path.join(DIR, cat)\n    norm = glob.glob(os.path.join(path, \"NORMAL/*.jpeg\"))\n    pneu = glob.glob(os.path.join(path, \"PNEUMONIA/*.jpeg\"))\n    all_normal.extend(norm)\n    all_pneumonia.extend(pneu)\n\nprint(f\"Total Pneumonia Images: {len(all_pneumonia)}\")\nprint(f\"Total Normal Images: {len(all_normal)}\")","metadata":{"execution":{"iopub.execute_input":"2024-10-16T07:55:51.309388Z","iopub.status.busy":"2024-10-16T07:55:51.30893Z","iopub.status.idle":"2024-10-16T07:55:51.340303Z","shell.execute_reply":"2024-10-16T07:55:51.33933Z","shell.execute_reply.started":"2024-10-16T07:55:51.309354Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"labels = ['Nomal', 'Pneumonia']\ntargets = [len(all_normal), len(all_pneumonia)]\n\nplt.style.use(\"ggplot\")\nplt.figure(figsize=(16, 9))\nplt.pie(x=targets, labels=labels, autopct=\"%1.1f%%\")\nplt.title(\"Image Category Distribution\")\nplt.show()","metadata":{"execution":{"iopub.execute_input":"2024-10-16T07:55:51.341638Z","iopub.status.busy":"2024-10-16T07:55:51.341326Z","iopub.status.idle":"2024-10-16T07:55:51.515816Z","shell.execute_reply":"2024-10-16T07:55:51.514716Z","shell.execute_reply.started":"2024-10-16T07:55:51.341606Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"* We can see that there's some good data imbalance, we have more data for Pneumonia Images then for the Normal Images.","metadata":{}},{"cell_type":"code","source":"# Shuffle and Get some images into new list\nrandom.shuffle(all_normal)\nrandom.shuffle(all_pneumonia)\nimages = all_normal[:50] + all_pneumonia[:50]","metadata":{"execution":{"iopub.execute_input":"2024-10-16T07:55:51.517742Z","iopub.status.busy":"2024-10-16T07:55:51.517219Z","iopub.status.idle":"2024-10-16T07:55:51.529583Z","shell.execute_reply":"2024-10-16T07:55:51.528493Z","shell.execute_reply.started":"2024-10-16T07:55:51.517691Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Basic X-Ray Images\n","metadata":{}},{"cell_type":"code","source":"fig=plt.figure(figsize=(15, 10))\ncolumns = 4; rows = 5\nfor i in range(1, columns*rows +1):\n    img = cv2.imread(images[i])\n    img = cv2.resize(img, (128, 128))\n    fig.add_subplot(rows, columns, i)\n    plt.imshow(img)\n    plt.axis(False)","metadata":{"execution":{"iopub.execute_input":"2024-10-16T07:55:51.532934Z","iopub.status.busy":"2024-10-16T07:55:51.532585Z","iopub.status.idle":"2024-10-16T07:55:52.965176Z","shell.execute_reply":"2024-10-16T07:55:52.964235Z","shell.execute_reply.started":"2024-10-16T07:55:51.532902Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Ben Graham's Method\n","metadata":{}},{"cell_type":"code","source":"fig=plt.figure(figsize=(15, 10))\ncolumns = 4; rows = 2\nfor i in range(1, columns*rows +1):\n    img = cv2.imread(images[i])\n    img = cv2.resize(img, (512, 512))\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n    img = cv2.addWeighted (img, 4, cv2.GaussianBlur(img, (0,0), 512/10), -4, 128)\n    fig.add_subplot(rows, columns, i)\n    plt.imshow(img)\n    plt.axis(False)\n","metadata":{"execution":{"iopub.execute_input":"2024-10-16T07:55:52.966543Z","iopub.status.busy":"2024-10-16T07:55:52.966233Z","iopub.status.idle":"2024-10-16T07:55:57.40339Z","shell.execute_reply":"2024-10-16T07:55:57.402423Z","shell.execute_reply.started":"2024-10-16T07:55:52.966509Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Fourier Method for Pixel Distribution","metadata":{}},{"cell_type":"code","source":"fig=plt.figure(figsize=(15, 10))\ncolumns = 4; rows = 2\nfor i in range(1, columns*rows +1):\n    img = cv2.imread(images[i])\n    img = cv2.resize(img, (512, 512))\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n    f = np.fft.fft2(img)\n    fshift = np.fft.fftshift(f)\n    magnitude_spectrum = 20*np.log(np.abs(fshift))\n    fig.add_subplot(rows, columns, i)\n    plt.imshow(magnitude_spectrum)\n    plt.axis(False)","metadata":{"execution":{"iopub.execute_input":"2024-10-16T07:55:57.405444Z","iopub.status.busy":"2024-10-16T07:55:57.404792Z","iopub.status.idle":"2024-10-16T07:55:58.855785Z","shell.execute_reply":"2024-10-16T07:55:58.854641Z","shell.execute_reply.started":"2024-10-16T07:55:57.405375Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"* Those images are basically magnitude spectrums, this helps in understanding where majority of growth is situated.","metadata":{}},{"cell_type":"markdown","source":"## Albumentations Visualization","metadata":{}},{"cell_type":"code","source":"chosen_image = cv2.imread(images[25])\n\nalbumentation_list = [\n    A.RandomSunFlare(p=1), \n    A.RandomFog(p=1), \n    A.RandomBrightnessContrast(p=1),  # Corrected\n    A.RandomCrop(p=1, height=512, width=512), \n    A.Rotate(p=1, limit=90),\n    A.RGBShift(p=1), \n    A.RandomSnow(p=1),\n    A.HorizontalFlip(p=1), \n    A.VerticalFlip(p=1), \n    A.HueSaturationValue(p=1, hue_shift_limit=20, sat_shift_limit=30, val_shift_limit=50)\n]\n\nimg_matrix_list = []\nbboxes_list = []\nfor aug_type in albumentation_list:\n    img = aug_type(image=chosen_image)['image']\n    img_matrix_list.append(img)\n\n# Include the original image at the start of the list\nimg_matrix_list.insert(0, chosen_image)\n\n# Updated titles list\ntitles_list = [\n    \"Original\", \"RandomSunFlare\", \"RandomFog\", \"RandomBrightnessContrast\", \n    \"RandomCrop\", \"Rotate\", \"RGBShift\", \"RandomSnow\", \n    \"HorizontalFlip\", \"VerticalFlip\", \"HSV\"\n]\n\n# Assuming plot_multiple_img is a function to display multiple images\nplot_multiple_img(img_matrix_list, titles_list, ncols=4, main_title=\"Different Types of Augmentations\")\n","metadata":{"execution":{"iopub.execute_input":"2024-10-16T07:55:58.860939Z","iopub.status.busy":"2024-10-16T07:55:58.86048Z","iopub.status.idle":"2024-10-16T07:56:05.350296Z","shell.execute_reply":"2024-10-16T07:56:05.349295Z","shell.execute_reply.started":"2024-10-16T07:55:58.860895Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Image Erosion","metadata":{}},{"cell_type":"code","source":"fig=plt.figure(figsize=(15, 10))\ncolumns = 5; rows = 2\nfor i in range(1, columns*rows +1):\n    img = cv2.imread(images[i])\n    img = cv2.resize(img, (512, 512))\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    kernel = np.ones((5, 5), np.uint8)\n    img_erosion = cv2.erode(img, kernel, iterations=3)\n    fig.add_subplot(rows, columns, i)\n    plt.imshow(img_erosion)\n    plt.axis(False)","metadata":{"execution":{"iopub.execute_input":"2024-10-16T07:56:05.351769Z","iopub.status.busy":"2024-10-16T07:56:05.351487Z","iopub.status.idle":"2024-10-16T07:56:06.437817Z","shell.execute_reply":"2024-10-16T07:56:06.43699Z","shell.execute_reply.started":"2024-10-16T07:56:05.351738Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Image Dilation","metadata":{}},{"cell_type":"code","source":"fig=plt.figure(figsize=(15, 10))\ncolumns = 5; rows = 2\nfor i in range(1, columns*rows +1):\n    img = cv2.imread(images[i])\n    img = cv2.resize(img, (512, 512))\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    kernel = np.ones((5, 5), np.uint8)\n    img_erosion = cv2.dilate(img, kernel, iterations=3)\n    fig.add_subplot(rows, columns, i)\n    plt.imshow(img_erosion)\n    plt.axis(False)","metadata":{"execution":{"iopub.execute_input":"2024-10-16T07:56:06.439423Z","iopub.status.busy":"2024-10-16T07:56:06.439092Z","iopub.status.idle":"2024-10-16T07:56:07.59256Z","shell.execute_reply":"2024-10-16T07:56:07.5917Z","shell.execute_reply.started":"2024-10-16T07:56:06.439372Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Canny Edge Detection","metadata":{}},{"cell_type":"code","source":"fig=plt.figure(figsize=(15, 10))\ncolumns = 5; rows = 2\nfor i in range(1, columns*rows +1):\n    img = cv2.imread(images[i])\n    img = cv2.resize(img, (512, 512))\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n    edges = cv2.Canny(img, 80, 100)\n    fig.add_subplot(rows, columns, i)\n    plt.imshow(edges)\n    plt.axis(False)","metadata":{"execution":{"iopub.execute_input":"2024-10-16T07:56:07.593905Z","iopub.status.busy":"2024-10-16T07:56:07.593617Z","iopub.status.idle":"2024-10-16T07:56:08.495432Z","shell.execute_reply":"2024-10-16T07:56:08.494525Z","shell.execute_reply.started":"2024-10-16T07:56:07.593874Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<div style=\"\n  background-color: #e3f2fd;\n  padding: 15px;\n  border-left: 6px solid #0d47a1;\n  border-radius: 8px;\n  font-family: 'Georgia', serif;\n  color: #01579b;\n  font-size: 28px;\n  text-align: center;\n  font-weight: bold;\n\">\n  üì• Reading the Data\n\n</div>\n","metadata":{}},{"cell_type":"code","source":"train_images = load_images_from_folder(train_pneumonia_dir)\ntest_images = load_images_from_folder(test_pneumonia_dir)\nvalid_images = load_images_from_folder(valid_pneumonia_dir)\n\nX = train_images + test_images + valid_images\n\nX = np.array(X)\n\nX = (X - 127.5) / 127.5\n\nprint(f\"Loaded {len(X)} images, each resized to {target_size}.\")","metadata":{"execution":{"iopub.execute_input":"2024-10-16T10:21:58.213545Z","iopub.status.busy":"2024-10-16T10:21:58.213172Z","iopub.status.idle":"2024-10-16T10:22:50.010947Z","shell.execute_reply":"2024-10-16T10:22:50.009818Z","shell.execute_reply.started":"2024-10-16T10:21:58.213514Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X.shape","metadata":{"execution":{"iopub.execute_input":"2024-10-16T10:22:50.012763Z","iopub.status.busy":"2024-10-16T10:22:50.012379Z","iopub.status.idle":"2024-10-16T10:22:50.021482Z","shell.execute_reply":"2024-10-16T10:22:50.020496Z","shell.execute_reply.started":"2024-10-16T10:22:50.012729Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"dataset = tf.data.Dataset.from_tensor_slices(X).shuffle(buffer_size=1000).batch(batch_size)","metadata":{"execution":{"iopub.execute_input":"2024-10-16T10:22:50.023296Z","iopub.status.busy":"2024-10-16T10:22:50.022958Z","iopub.status.idle":"2024-10-16T10:22:54.257923Z","shell.execute_reply":"2024-10-16T10:22:54.256948Z","shell.execute_reply.started":"2024-10-16T10:22:50.023264Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<div style=\"\n  background-color: #e3f2fd;\n  padding: 15px;\n  border-left: 6px solid #0d47a1;\n  border-radius: 8px;\n  font-family: 'Georgia', serif;\n  color: #01579b;\n  font-size: 28px;\n  text-align: center;\n  font-weight: bold;\n\">\n  üß† Modeling\n\n</div>\n","metadata":{}},{"cell_type":"code","source":"generator = tf.keras.Sequential()\n\n# First layer: Dense + BatchNorm + LeakyReLU, input shape is the noise vector (100,)\ngenerator.add(layers.Dense(16 * 16 * 256, use_bias=False, input_shape=(100,)))\ngenerator.add(layers.BatchNormalization())\ngenerator.add(layers.LeakyReLU())\n\n# Reshape the output to (16, 16, 256)\ngenerator.add(layers.Reshape((16, 16, 256)))\n\n# Layer 2: Upsample to (32, 32, 128) with Conv2DTranspose\ngenerator.add(layers.Conv2DTranspose(128, (5, 5), strides=(2, 2), padding='same', use_bias=False))\ngenerator.add(layers.BatchNormalization())\ngenerator.add(layers.LeakyReLU())\n\n# Layer 3: Upsample to (64, 64, 64) with Conv2DTranspose\ngenerator.add(layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False))\ngenerator.add(layers.BatchNormalization())\ngenerator.add(layers.LeakyReLU())\n\n# Layer 4: Upsample to (128, 128, 32) with Conv2DTranspose\ngenerator.add(layers.Conv2DTranspose(32, (5, 5), strides=(2, 2), padding='same', use_bias=False))\ngenerator.add(layers.BatchNormalization())\ngenerator.add(layers.LeakyReLU())\n\n# Final output layer: Conv2DTranspose to get the 128x128x3 RGB image\ngenerator.add(layers.Conv2DTranspose(3, (5, 5), strides=(1, 1), padding='same', use_bias=False, activation='tanh'))\n\n# Model summary\ngenerator.summary()\n","metadata":{"execution":{"iopub.execute_input":"2024-10-16T10:50:12.727769Z","iopub.status.busy":"2024-10-16T10:50:12.72706Z","iopub.status.idle":"2024-10-16T10:50:12.737796Z","shell.execute_reply":"2024-10-16T10:50:12.73682Z","shell.execute_reply.started":"2024-10-16T10:50:12.727728Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"discriminator = tf.keras.Sequential()\n\n# First layer: Input shape (128, 128, 3) -> Downsample to (64, 64, 64)\ndiscriminator.add(layers.Conv2D(64, kernel_size=4, strides=2, padding='same', input_shape=(128, 128, 3), use_bias=False))\ndiscriminator.add(layers.LeakyReLU(0.2))\n\n# Second layer: Downsample to (32, 32, 128)\ndiscriminator.add(layers.Conv2D(128, kernel_size=4, strides=2, padding='same', use_bias=False))\ndiscriminator.add(layers.BatchNormalization())\ndiscriminator.add(layers.LeakyReLU(0.2))\n\n# Third layer: Downsample to (16, 16, 256)\ndiscriminator.add(layers.Conv2D(256, kernel_size=4, strides=2, padding='same', use_bias=False))\ndiscriminator.add(layers.BatchNormalization())\ndiscriminator.add(layers.LeakyReLU(0.2))\n\n# Fourth layer: Downsample to (8, 8, 512)\ndiscriminator.add(layers.Conv2D(512, kernel_size=4, strides=2, padding='same', use_bias=False))\ndiscriminator.add(layers.BatchNormalization())\ndiscriminator.add(layers.LeakyReLU(0.2))\n\n# Fifth layer: Downsample to (4, 4, 512) and then to a single value\ndiscriminator.add(layers.Conv2D(1, kernel_size=4, strides=1, padding='valid', use_bias=False))\ndiscriminator.add(layers.Flatten())  # Flatten to a single output\ndiscriminator.add(layers.Activation('sigmoid'))  # Binary classification (real or fake)\n\n# Model summary\ndiscriminator.summary()\n","metadata":{"execution":{"iopub.execute_input":"2024-10-16T10:50:12.929736Z","iopub.status.busy":"2024-10-16T10:50:12.928933Z","iopub.status.idle":"2024-10-16T10:50:12.939094Z","shell.execute_reply":"2024-10-16T10:50:12.938168Z","shell.execute_reply.started":"2024-10-16T10:50:12.929702Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n\ndef discriminator_loss(real_output, fake_output):\n    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n    total_loss = real_loss + fake_loss\n    return total_loss\n\ndef generator_loss(fake_output):\n    return cross_entropy(tf.ones_like(fake_output), fake_output)\n\ngenerator_optimizer = tf.keras.optimizers.Adam(0.001)\ndiscriminator_optimizer = tf.keras.optimizers.Adam(0.0002)","metadata":{"execution":{"iopub.execute_input":"2024-10-16T10:50:13.126939Z","iopub.status.busy":"2024-10-16T10:50:13.126108Z","iopub.status.idle":"2024-10-16T10:50:13.136944Z","shell.execute_reply":"2024-10-16T10:50:13.136215Z","shell.execute_reply.started":"2024-10-16T10:50:13.126902Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"@tf.function\ndef train_step(images, batch_size):\n    noise = tf.random.normal([batch_size, 100])\n\n    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n        generated_images = generator(noise, training=True)\n\n        real_output = discriminator(images, training=True)\n        fake_output = discriminator(generated_images, training=True)\n\n        gen_loss = generator_loss(fake_output)\n        disc_loss = discriminator_loss(real_output, fake_output)\n\n    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n\n    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n\n    return gen_loss, disc_loss","metadata":{"execution":{"iopub.execute_input":"2024-10-16T10:50:13.386889Z","iopub.status.busy":"2024-10-16T10:50:13.386048Z","iopub.status.idle":"2024-10-16T10:50:13.394249Z","shell.execute_reply":"2024-10-16T10:50:13.393225Z","shell.execute_reply.started":"2024-10-16T10:50:13.38685Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def train(dataset, epochs, batch_size):\n    \"\"\"\n    Trains the GAN model for a specified number of epochs.\n    \n    Parameters:\n        dataset (tf.data.Dataset): The dataset containing real images, usually preprocessed and batched.\n        epochs (int): Number of epochs to train the model.\n        batch_size (int): The size of batches used during training.\n    \"\"\"\n    g_losses,d_losses = [],[]\n    for epoch in range(epochs):\n        print(f\"Epoch {epoch+1}/{epochs}\")\n        \n        for image_batch in dataset:\n            gen_loss, disc_loss = train_step(image_batch, batch_size)\n            g_losses.append(gen_loss)\n            d_losses.append(disc_loss)\n\n        \n        print(f\"Generator Loss: {gen_loss}, Discriminator Loss: {disc_loss}\")\n        \n        \n        if (epoch + 1) % 50 == 0:  # Save model every 50 epochs\n            generator.save(f'generator_epoch_{epoch+1}.h5')\n            discriminator.save(f'discriminator_epoch_{epoch+1}.h5')\n            \n    return g_losses,d_losses","metadata":{"execution":{"iopub.execute_input":"2024-10-16T10:50:13.604479Z","iopub.status.busy":"2024-10-16T10:50:13.604054Z","iopub.status.idle":"2024-10-16T10:50:13.611504Z","shell.execute_reply":"2024-10-16T10:50:13.61051Z","shell.execute_reply.started":"2024-10-16T10:50:13.604433Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"g_losses,d_losses = train(dataset, epochs=300, batch_size=batch_size)","metadata":{"execution":{"iopub.execute_input":"2024-10-16T10:50:14.533048Z","iopub.status.busy":"2024-10-16T10:50:14.532178Z","iopub.status.idle":"2024-10-16T11:53:18.992317Z","shell.execute_reply":"2024-10-16T11:53:18.991335Z","shell.execute_reply.started":"2024-10-16T10:50:14.532994Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"noise = tf.random.normal([10, 100])","metadata":{"execution":{"iopub.execute_input":"2024-10-16T11:53:19.541108Z","iopub.status.busy":"2024-10-16T11:53:19.540777Z","iopub.status.idle":"2024-10-16T11:53:19.546638Z","shell.execute_reply":"2024-10-16T11:53:19.545739Z","shell.execute_reply.started":"2024-10-16T11:53:19.541074Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"images = generator(noise, training=False)","metadata":{"execution":{"iopub.execute_input":"2024-10-16T11:53:19.549507Z","iopub.status.busy":"2024-10-16T11:53:19.549131Z","iopub.status.idle":"2024-10-16T11:53:19.56938Z","shell.execute_reply":"2024-10-16T11:53:19.568546Z","shell.execute_reply.started":"2024-10-16T11:53:19.549462Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for image in images:\n    plt.imshow(image.numpy().reshape(128,128, 3))\n    plt.show()","metadata":{"execution":{"iopub.execute_input":"2024-10-16T11:53:19.570762Z","iopub.status.busy":"2024-10-16T11:53:19.570467Z","iopub.status.idle":"2024-10-16T11:53:22.299428Z","shell.execute_reply":"2024-10-16T11:53:22.298554Z","shell.execute_reply.started":"2024-10-16T11:53:19.570732Z"},"trusted":true},"outputs":[],"execution_count":null}]}